"""
Example script for identifying which high-level categories are present in a text.
High-level categories are taken from the THINGS+ dataset (generated by WordNet).
"""
from collections import Counter
from pathlib import Path
import pandas as pd
import spacy
import tqdm


# The filepath of the categories file (should never change).
import_path_categories = "../sourcedata/category53_longFormat.tsv"

# The filepath of the dream reports file.
import_path_reports = "../sourcedata/Reports.csv"

# The column name of the dream reports (should be present in the dream reports file).
reports_column = "Text of Report"

# Load both files.
df_categories = pd.read_csv(import_path_categories, sep="\t")
df_reports = pd.read_csv(import_path_reports)

# Extract a dictionary that maps words to categories.
word2category_mapping = df_categories.set_index("Word")["category"].to_dict()

# Extract the dream reports as a list.
reports = df_reports["Text of Report"].tolist()

# Load the spaCy model.
nlp = spacy.load("en_core_web_sm")

# Create an empty list to hold the results.
results = []
# Loop over each dream report.
for report in tqdm.tqdm(reports):
    # Tokenize and lemmatize the dream report (i.e., split into words and get root word form).
    doc = nlp(report)
    lemmas = [token.lemma_ for token in doc]
    # Get word categories for each word that belongs to one.
    lemma_categories = [word2category_mapping.get(lemma, "none") for lemma in lemmas]
    # Get counts of each word category.
    category_counts = Counter(lemma_categories)
    # Append this result to the results list.
    results.append(category_counts)

# Convert the results to a DataFrame.
df = pd.Series(results).apply(pd.Series).fillna(0).astype(int)
